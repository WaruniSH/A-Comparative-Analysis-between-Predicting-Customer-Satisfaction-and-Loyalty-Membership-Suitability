{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "dataset=pd.read_csv('/content/restaurant_customer_satisfaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing first five rows of the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing last three raws of the dataset\n",
    "dataset.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing data raws upto zero to twenty 3 by 3\n",
    "dataset.loc[0:20:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing the dimention of the dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the coloumns names of the dataset\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing dataset as a dataframe\n",
    "df=pd.DataFrame(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the detailed informations of the features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing specific colomn only\n",
    "df['Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing specific rows of a specific colomn\n",
    "df.loc[0:1,'Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Age\", \"Gender\", \"MealType\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mean of FoodRating colomn\n",
    "meann = df['FoodRating'].mean()\n",
    "meann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round the mean in to two points\n",
    "round(meann,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the data types of the colomns\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the total number of null values in the data set according to the features\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "dataset = dataset.drop(['CustomerID','Gender', 'GroupSize', 'MealType', 'OnlineReservation', 'DeliveryOrder', 'WaitTime', 'AverageSpend'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the dataset after dropping the unwanted colomns\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the statistical description of the data(only Numarical data will describe)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a copy of dataset\n",
    "original_dataset = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#differntiate the data(numarical/catergorical/bianary/non-binary)\n",
    "non_binary_categorical_columns =['VisitFrequency', 'PreferredCuisine', 'TimeOfVisit', 'DiningOccasion']\n",
    "numarical_columns = ['Age', 'Income',  'LoyaltyProgramMember', 'ServiceRating', 'FoodRating', 'AmbianceRating','HighSatisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one-hot encoding\n",
    "VisitFrequency_dummie = pd.get_dummies(original_dataset['VisitFrequency'], prefix = 'VisitFrequency')\n",
    "PreferredCuisine_dummie = pd.get_dummies(original_dataset['PreferredCuisine'], prefix = 'PreferredCuisine')\n",
    "TimeOfVisit_dummie = pd.get_dummies(original_dataset['TimeOfVisit'], prefix = 'TimeOfVisit')\n",
    "DiningOccasion_dummie = pd.get_dummies(original_dataset['DiningOccasion'], prefix = 'DiningOccasion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the non-binary categorical colomns from the copy of dataset and stote in another variable\n",
    "new_data = original_dataset.drop(non_binary_categorical_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the dummies\n",
    "OH_data = pd.concat([new_data,VisitFrequency_dummie,PreferredCuisine_dummie,TimeOfVisit_dummie,DiningOccasion_dummie], axis=1)\n",
    "print (OH_data)\n",
    "\n",
    "\n",
    "OH_data.columns = OH_data.columns.astype(str)\n",
    "\n",
    "OH_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a copy of encoded data and check the null values\n",
    "encoded_data = OH_data.copy()\n",
    "encoded_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for numerical features\n",
    "numeric_columns = ['Income', 'HighSatisfaction',  'LoyaltyProgramMember', 'ServiceRating', 'FoodRating', 'AmbianceRating']\n",
    "for column in numeric_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df[column].dropna(), kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.displot(encoded_data[\"Income\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(encoded_data[\"HighSatisfaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(encoded_data[\"LoyaltyProgramMember\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the boxplots of some features\n",
    "plt.boxplot(encoded_data['ServiceRating'])\n",
    "plt.title('Service Rating Explot')\n",
    "plt.ylabel('Service Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(encoded_data['FoodRating'])\n",
    "plt.title('Food Rating Explot')\n",
    "plt.ylabel('Food Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(encoded_data['AmbianceRating'])\n",
    "plt.title('Ambiance Rating Explot')\n",
    "plt.ylabel('AmbianceRating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the pie charts for some features\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(dataset['LoyaltyProgramMember'].value_counts(), labels=original_dataset['LoyaltyProgramMember'].value_counts().index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Loyality Program Member Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(dataset['PreferredCuisine'].value_counts(), labels=original_dataset['PreferredCuisine'].value_counts().index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Preferred Cuisine Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(dataset['VisitFrequency'].value_counts(), labels=original_dataset['VisitFrequency'].value_counts().index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Visit Frequency Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(dataset['DiningOccasion'].value_counts(), labels=original_dataset['DiningOccasion'].value_counts().index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Dining Occasion Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and visualizing correlation of each feature with the target value\n",
    "corr_matrix = encoded_data.corr()\n",
    "corr_with_target = corr_matrix['LoyaltyProgramMember'].sort_values(ascending=False)\n",
    "print(corr_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the corerelation of target variable with independent variables\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr_with_target.drop('LoyaltyProgramMember').plot(kind='bar', color='green')\n",
    "plt.title('Correlation with Target Variable (Loyalty Program Member)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlation')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the heatmap to further visulization of correlation\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.1)\n",
    "plt.title('Correlation Heatmap of the Loyality Program Member (Target Variable) ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the first five rowas of the encoded data and se  the features\n",
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the target variable from the encoded data and store in another variable\n",
    "independant_features = encoded_data.columns.drop(['LoyaltyProgramMember']).tolist()\n",
    "\n",
    "#define the X and Y for split the dataset\n",
    "y = encoded_data['LoyaltyProgramMember']\n",
    "X = encoded_data[independant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Standardization\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(train_X)\n",
    "# X_test_scaled = scaler.transform(val_X)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "X_normalized = scaler.fit_transform(X) # Noralized X\n",
    "\n",
    "X_normalized.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_normalized, y, random_state = 10 ,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of algorithms\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the training data for algorithms\n",
    "lr.fit(train_X,train_y)\n",
    "knn.fit(train_X,train_y)\n",
    "svc.fit(train_X,train_y)\n",
    "rf.fit(train_X,train_y)\n",
    "gb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predictions using validation or the testing data\n",
    "y_pred1 = lr.predict(val_X)\n",
    "y_pred2 = knn.predict(val_X)\n",
    "y_pred3 = svc.predict(val_X)\n",
    "y_pred4 = rf.predict(val_X)\n",
    "y_pred5 = gb.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the accuracy of each algorithms by using predicted values\n",
    "print('Logistic Regression Accuracy:',accuracy_score(val_y,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN Accuracy:',accuracy_score(val_y,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVC Accuracy:',accuracy_score(val_y,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest Accuracy:',accuracy_score(val_y,y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient Boosting Accuracy:',accuracy_score(val_y,y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the models\n",
    "pickle.dump(lr,open('model.pkl','wb'))\n",
    "pickle.dump(svc,open('scaler.pkl','wb'))\n",
    "pickle.dump(knn,open('knn.pkl','wb'))\n",
    "pickle.dump(rf,open('rf.pkl','wb'))\n",
    "pickle.dump(gb,open('gb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gradient_bossting.sav'\n",
    "\n",
    "# Save the model\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(gb, file)\n",
    "print(f\"Model saved as {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
